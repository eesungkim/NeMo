# Masking Context Synchronization - Summary & Solution

## ‚ö†Ô∏è Issue Identified

**You're absolutely right!** When using dynamic `att_context_size`, the masking `left_context_size` needs to be synchronized!

### The Problem

```python
# Attention context limited to 160 frames
model.encoder.att_context_size = [160, 0]

# But masking uses unlimited context
model.mask_processor.left_context_size = -1  # ‚ùå

# Result: Masking can mask frames beyond attention window!
# Frame 180 gets masked, but model can only attend up to frame 160
# ‚Üí Train-inference inconsistency
```

---

## ‚úÖ Solution Implemented

### 1. Updated Masking Module

**File**: `nemo/collections/asr/modules/ssl_modules/masking.py`

**Added `effective_left_context` parameter**:
```python
def forward_causal(
    self,
    input_feats,
    input_lengths,
    current_frame=None,
    effective_left_context=None  # NEW: Override left_context_size
):
    # Use effective context if provided, else use configured value
    left_context_size = effective_left_context if effective_left_context is not None else self.left_context_size
    # ... rest of logic uses left_context_size
```

### 2. Created Utility Functions

**File**: `nemo/collections/asr/parts/utils/streaming_utils.py`

```python
from nemo.collections.asr.parts.utils.streaming_utils import (
    sync_masking_context_with_attention,
    set_dynamic_context
)

# Sync manually
sync_masking_context_with_attention(model)

# Or set with auto-sync
set_dynamic_context(model, [160, 0], sync_masking=True)
```

---

## üöÄ How to Use

### Option 1: Manual Sync (Simple)

```python
# Set attention context
model.encoder.att_context_size = [160, 0]

# Sync masking context
from nemo.collections.asr.parts.utils.streaming_utils import sync_masking_context_with_attention
sync_masking_context_with_attention(model)

# Now both are synced!
```

### Option 2: Use Helper Function (Recommended)

```python
from nemo.collections.asr.parts.utils.streaming_utils import set_dynamic_context

# One call does both
set_dynamic_context(model, [160, 0], sync_masking=True)
# ‚úì Attention context set to [160, 0]
# ‚úì Masking context synced to 160
```

### Option 3: Use Presets (Easiest)

```python
from nemo.collections.asr.parts.utils.streaming_utils import set_dynamic_context

# Use preset names
set_dynamic_context(model, 'low')        # [160, 0]
set_dynamic_context(model, 'medium')     # [240, 0]
set_dynamic_context(model, 'high')       # [320, 0]
set_dynamic_context(model, 'unlimited')  # [-1, 0]
```

---

## üìä Sync Rules

| Attention Context | Masking Context | Notes |
|-------------------|-----------------|-------|
| `[80, 0]` | `80` | Match exactly |
| `[160, 0]` | `160` | Match exactly |
| `[320, 0]` | `320` | Match exactly |
| `[-1, 0]` | `-1` | Both unlimited |

**Rule**: Masking `left_context_size` should match attention `att_context_size[0]`

---

## üéØ Updated Training Workflow

### Multi-Context Training (Recommended)

```yaml
# Config: nest_fast-conformer_streaming_dynamic.yaml
encoder:
  att_context_size: [[80,0], [160,0], [320,0], [-1,0]]
  att_context_probs: [0.25, 0.25, 0.25, 0.25]

masking:
  causal: true
  left_context_size: -1  # Will be synced per-batch during training
```

**During training**: NeMo samples attention context per batch. The masking should ideally sync, but this requires modifying the training loop.

**For inference**: Use the utility functions to manually sync.

---

## üîß Complete Inference Example

```python
from nemo.collections.asr.models import EncDecDenoiseMaskedTokenPredModel
from nemo.collections.asr.parts.utils.streaming_utils import set_dynamic_context

# Load model
model = EncDecDenoiseMaskedTokenPredModel.restore_from("model.nemo")

# Scenario 1: Low latency
set_dynamic_context(model, 'low', sync_masking=True)
output1 = model.forward(audio, lengths, apply_mask=False)

# Scenario 2: High accuracy
set_dynamic_context(model, 'high', sync_masking=True)
output2 = model.forward(audio, lengths, apply_mask=False)

# Scenario 3: Custom context
set_dynamic_context(model, [200, 0], sync_masking=True)
output3 = model.forward(audio, lengths, apply_mask=False)
```

---

## üìà Impact of Syncing

### Without Sync (‚ùå Inconsistent)

```
Attention window: [Frame 0 ... Frame 160]
Masking window:   [Frame 0 ........... Frame 300 ........... Frame 500]
                                      ‚Üë                         ‚Üë
                                  Frames 161-500 masked but not in attention!
                                  Model can't learn from them!
```

### With Sync (‚úÖ Consistent)

```
Attention window: [Frame 0 ... Frame 160]
Masking window:   [Frame 0 ... Frame 160]
                                        ‚Üë
                              Perfect alignment!
```

---

## ‚úÖ Summary

**Problem**: Masking context doesn't auto-sync with dynamic attention context
**Impact**: Inconsistent training, wasted computation
**Solution**:
1. ‚úÖ Added `effective_left_context` parameter to masking
2. ‚úÖ Created `streaming_utils.py` with sync functions
3. ‚úÖ Updated documentation

**Status**: Fixed! Use `set_dynamic_context()` for automatic syncing.

---

## üìÅ Files Modified/Created

1. ‚úÖ **Modified**: `nemo/collections/asr/modules/ssl_modules/masking.py`
   - Added `effective_left_context` parameter to `forward()`
   - Added `effective_left_context` parameter to `forward_causal()`

2. ‚úÖ **Created**: `nemo/collections/asr/parts/utils/streaming_utils.py`
   - `sync_masking_context_with_attention()` - Sync helper
   - `set_dynamic_context()` - Set context with auto-sync

3. ‚úÖ **Created**: `MASKING_CONTEXT_SYNC.md` - Full documentation
4. ‚úÖ **Created**: `MASKING_SYNC_SUMMARY.md` - This file

---

## üöÄ Quick Reference

```python
# Import utilities
from nemo.collections.asr.parts.utils.streaming_utils import set_dynamic_context

# Load model
model = EncDecDenoiseMaskedTokenPredModel.restore_from("model.nemo")

# Set context with auto-sync
set_dynamic_context(model, 'low')        # [160, 0]
set_dynamic_context(model, [240, 0])     # Custom
set_dynamic_context(model, 'unlimited')  # [-1, 0]

# Process audio
output = model.forward(audio, lengths, apply_mask=False)
```

**That's it! Masking now stays in sync with attention context.** ‚úÖ
